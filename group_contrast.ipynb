{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run cross-group analyses that lyman doesn't suppport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#os and i/o\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from os.path import abspath\n",
    "\n",
    "#scientific computing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats, optimize\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "import random as rd\n",
    "import scipy.stats\n",
    "\n",
    "##nipype\n",
    "import nibabel as nib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preliminary housekeeping\n",
    "home_dir = '/data/home/iballard/mag/'\n",
    "subj_file = home_dir + 'subjects.txt'\n",
    "sub_list = list(np.loadtxt(subj_file,'string'))\n",
    "os.chdir(home_dir)\n",
    "exps = ['mag']\n",
    "runs = map(str,range(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_dir = home_dir + 'analysis/mag/randomise/'\n",
    "if not os.path.exists(group_dir):\n",
    "    os.mkdir(group_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Make design file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:workflow:['check', 'execution', 'logging']\n",
      "INFO:workflow:Running serially.\n",
      "INFO:workflow:Executing node model in dir: /data/home/iballard/fd/analysis/group_ser_sim_4mm_PEmb/design/model\n",
      "INFO:workflow:Collecting precomputed outputs\n",
      "INFO:workflow:Executing node sinker in dir: /data/home/iballard/fd/analysis/group_ser_sim_4mm_PEmb/design/sinker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02670384  0.0166462   0.01692453 -0.00308281 -0.00612884 -0.01236596\n",
      "  0.03474843  0.03591418  0.00109689 -0.02691963 -0.00103481  0.00214077\n",
      "  0.03820496 -0.00154382 -0.01608614  0.01880507 -0.04014717 -0.00477828\n",
      " -0.03147572 -0.03426227 -0.03910758 -0.04015113  0.03599758  0.00682268\n",
      " -0.00073862  0.01846181  0.01704517 -0.0092812   0.02781854 -0.04014885\n",
      " -0.00724877  0.017171  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f10b42a4a10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternatively, make correlation design file\n",
    "# cov = np.loadtxt(home_dir + '/analysis/omegas_powell.txt')\n",
    "# cov = np.loadtxt(home_dir + 'vta_mb.txt')\n",
    "# cov = [x for x in cov if x> -5000]\n",
    "cov = pd.read_csv(home_dir + 'ser_r2_diff.csv')\n",
    "cov  = cov['diff_norm'].values \n",
    "cov = cov - np.mean(cov)\n",
    "print cov\n",
    "##make regressor and contrast inputs according to FSL rules for paired ttest\n",
    "# regressors = dict(cov = list(cov) )\n",
    "regressors = dict(cov = list(cov))\n",
    "contrasts=[['ser-corr','T',['cov'],[1]]]\n",
    "# regressors = dict(mean = list(np.ones(len(cov))))\n",
    "# contrasts=[['ser-corr','T',['mean'],[1]]]\n",
    "\n",
    "##set up WF so I can control where outputs go\n",
    "model = Node(fsl.MultipleRegressDesign(regressors = regressors, contrasts = contrasts),name='model')\n",
    "wf = Workflow(name = 'design',base_dir = group_dir)\n",
    "sink = Node(DataSink(),name = 'sinker',base_directory = group_dir)\n",
    "wf.connect(model,'design_con',sink,'output.@con')\n",
    "wf.connect(model,'design_grp',sink,'output.@grp')\n",
    "wf.connect(model,'design_mat',sink,'output.@mat')\n",
    "wf.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge the 3d files from ffx analysis into concatenated 4d files\n",
    "images = ['cope']\n",
    "ims_to_files = {'cope':'cope1.nii.gz'}\n",
    "contrast = 'high_minus_low'\n",
    "\n",
    "for f in images:\n",
    "    out_dir = group_dir + contrast\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    \n",
    "    #add files to merge command\n",
    "    out_f = out_dir + '/' + f + '_merged.nii.gz'\n",
    "    os.remove(out_f)\n",
    "    if not os.path.exists(out_f):\n",
    "        cmd_str = ['fslmerge','-t',out_f]\n",
    "\n",
    "        for exp in ['mag']: #order matters now\n",
    "            for sub in sub_list:\n",
    "                sub_dir = home_dir + '/analysis/' + exp + '/' + sub \n",
    "                sub_f = sub_dir + '/reg/mni/smoothed/high_minus_low.nii.gz'\n",
    "                \n",
    "#                 sub_f = sub_dir + '/ffx/mni/smoothed/' + contrast + '/' + ims_to_files[f]\n",
    "                cmd_str.append(sub_f)\n",
    "        cmd_str = ' '.join(cmd_str)\n",
    "        os.system(cmd_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for exp in ['mag']: #order matters now\n",
    "    for sub in sub_list:\n",
    "        sub_dir = home_dir + '/analysis/' + exp + '/' + sub + '/reg/mni/smoothed/'\n",
    "        f1 = sub_dir + '/run_1/cope25_warp.nii.gz' \n",
    "        f2 = sub_dir + '/run_2/cope25_warp.nii.gz'\n",
    "        out1 = sub_dir + 'low.nii.gz'\n",
    "        \n",
    "        cmd = ['fslmaths',f1,'-add',f2,out1]\n",
    "        cmd = ' '.join(cmd)\n",
    "        os.system(cmd)\n",
    "        \n",
    "        f1 = sub_dir + '/run_3/cope25_warp.nii.gz' \n",
    "        f2 = sub_dir + '/run_4/cope25_warp.nii.gz'\n",
    "        out2 = sub_dir + 'high.nii.gz'\n",
    "        \n",
    "        cmd = ['fslmaths',f1,'-add',f2,out2]\n",
    "        cmd = ' '.join(cmd)      \n",
    "        os.system(cmd)\n",
    "\n",
    "        out3 = sub_dir + 'high_minus_low'\n",
    "        cmd = ['fslmaths',out1,'-add',out2,out3]\n",
    "        cmd = ' '.join(cmd) \n",
    "        os.system(cmd)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Do fitting with randomise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_dir = group_dir + contrast\n",
    "stat_file = im_dir + '/cope_merged.nii.gz'\n",
    "mask_file = home_dir + '/analysis/' + exp + '/group/mni/' + contrast + '/mask.nii.gz'\n",
    "\n",
    "cmd_str = ['randomise','-i',stat_file,'-o',im_dir,'-m',mask_file,'-T','-v','5','-1','-n','250']\n",
    "cmd_str = ' '.join(cmd_str)\n",
    "os.system(cmd_str)\n",
    "# print cmd_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#do fitting with randomise\n",
    "#input image files\n",
    "def randomise(in_tuple):\n",
    "    contrast,exp,altmodel = in_tuple\n",
    "\n",
    "    im_dir = group_dir + contrast + '/'\n",
    "    if not os.path.exists(im_dir):\n",
    "        os.mkdir(im_dir)\n",
    "        \n",
    "#     stat_file = im_dir + 'cope_' + exp + '_merged.nii.gz'\n",
    "#     mask_file = home_dir + '/analysis/ser_4mm-' + altmodel + '/group/mni/' + contrast + '/mask.nii.gz'\n",
    "#     cmd = ['randomise','-i',stat_file,'-o',im_dir,'-m', mask_file,'-T','-1','-n','1000']\n",
    "#     cmd = ' '.join(cmd)\n",
    "#     os.system(cmd)\n",
    "\n",
    "    #input design files\n",
    "    stat_file = im_dir + '/corr/' + 'cope_' + exp + '_merged.nii.gz'\n",
    "    out_dir = im_dir + '/corr/'\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    mask_file = home_dir + '/analysis/ser_4mm-' + altmodel + '/group/mni/' + contrast + '/mask.nii.gz'\n",
    "    design_dir = group_dir + '/design/sinker/output/'\n",
    "    t_con_file = design_dir + 'design.con'\n",
    "    cov_split_file = design_dir + 'design.grp'\n",
    "    design_file = design_dir + 'design.mat'\n",
    "    cmd_str = ['randomise','-i',stat_file,'-o',out_dir,'-d',design_file,\n",
    "               '-t',t_con_file,'-m',mask_file,'-n','1000','-D','-T']\n",
    "    cmd_str = ' '.join(cmd_str)\n",
    "    os.system(cmd_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_tuples = [('PE_mb','ser','PEfb-diff'),('PE_mb_state','ser','PEfb-diff'),\n",
    "            ('state','ser','PEfb-diff')]\n",
    "pool = multiprocessing.Pool(processes = len(in_tuples))\n",
    "pool.map(randomise,in_tuples)\n",
    "pool.terminate()\n",
    "pool.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
