{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat dataset according to BIDS specification for uploading to OpenfMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os and i/o\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dir(dir_name):\n",
    "    if not op.exists(dir_name):\n",
    "        os.mkdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_link(old,new):\n",
    "    if not op.exists(new):\n",
    "        cmd = ['ln','-s',old,new]\n",
    "        cmd = ' '.join(cmd)\n",
    "        os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preliminary housekeeping\n",
    "home_dir = '/data/home/iballard/mag/'\n",
    "subj_file = home_dir + 'subjects.txt'\n",
    "sub_list = list(np.loadtxt(subj_file,'string'))\n",
    "os.chdir(home_dir)\n",
    "bids_dir = home_dir + '/mag-BIDS/'\n",
    "make_dir(bids_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get new sub names\n",
    "sub_map = {}\n",
    "for n,sub in enumerate(sub_list):\n",
    "    \n",
    "    if n < 9:\n",
    "        val = '0' + str(n + 1)\n",
    "    else:\n",
    "        val = str(n + 1)\n",
    "\n",
    "    sub_map[sub] = 'sub-' + val\n",
    "\n",
    "s = pd.DataFrame({'participant_id': sorted(sub_map.values())})\n",
    "s.to_csv(bids_dir + 'participants.tsv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize directories\n",
    "for sub in sub_list:\n",
    "    #make new sub dir\n",
    "    sub_dir = bids_dir + sub_map[sub]\n",
    "    make_dir(sub_dir)\n",
    "    \n",
    "    #make new anat dir\n",
    "    anat = op.join(sub_dir, 'anat')\n",
    "    make_dir(anat)\n",
    "    \n",
    "    #make new func dir\n",
    "    func = op.join(sub_dir, 'func')\n",
    "    make_dir(func) \n",
    "   \n",
    "    #make new fmap dir\n",
    "    fmap = op.join(sub_dir, 'fmap')\n",
    "    make_dir(fmap) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set up anat files\n",
    "for sub in sub_list:\n",
    "    new_anat = op.join(bids_dir, sub_map[sub], 'anat',sub_map[sub] + '_T1w.nii.gz')\n",
    "\n",
    "    t1 = op.join(home_dir,'data',sub,'anat','st1_0000.nii.gz')\n",
    "    make_link(t1,new_anat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set up func files\n",
    "for sub in sub_list:\n",
    "    func = glob.glob(op.join(home_dir,'data',sub,'func','*.nii.gz'))\n",
    "    \n",
    "    for f in func:\n",
    "        run = f.split('/')[-1].split('.')[0][-1]\n",
    "        new_func = op.join(bids_dir, sub_map[sub], 'func',\n",
    "                           sub_map[sub] + '_task-mag_run-0' + run + '_bold')\n",
    "        make_link(f,new_func + '.nii.gz')\n",
    "        \n",
    "        #json info\n",
    "        if sub[0:3]== 'asu':\n",
    "            info = op.join(home_dir,'asu_subs_info.json')\n",
    "        else:\n",
    "            info = op.join(home_dir,'princeton_subs_info.json')\n",
    "        \n",
    "        make_link(info,new_func + '.json')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set up onset files\n",
    "all_data = op.join(home_dir,'subj_params.csv')\n",
    "all_data = pd.read_csv(all_data)\n",
    "for sub in sub_list:\n",
    "    \n",
    "    if sub == 'asu4':\n",
    "        subid = 'asu04'\n",
    "    elif sub == 'asu8':\n",
    "        subid = 'asu08'\n",
    "    else:\n",
    "        subid = sub\n",
    "        \n",
    "    sub_df = all_data[all_data['sub'] == subid]\n",
    "    \n",
    "    sub_df = sub_df.rename(index=str, columns={\"condition\": \"trial_type\"})\n",
    "    \n",
    "    sub_df['response_time'] = sub_df['duration']\n",
    "    sub_df['duration'] = sub_df['duration'] + 5 #fatter HRF in PFC\n",
    "        \n",
    "    for run in set(sub_df['run']):\n",
    "\n",
    "        run_df = sub_df[sub_df['run'] == run]\n",
    "\n",
    "    \n",
    "        out_f = op.join(bids_dir, sub_map[sub], 'func',\n",
    "                        sub_map[sub] + '_task-mag_run-0' + str(run) + '_events.tsv')\n",
    "                \n",
    "        run_df.to_csv(out_f, sep = '\\t', index = False,\n",
    "                     columns = ['onset','duration','response_time','amountSS','amountLL',\n",
    "                               'delaySS','delayLL','choice','SV_SS',\n",
    "                               'SV_LL','SV_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set up fmap files\n",
    "for sub in sub_list:\n",
    "    func = glob.glob(op.join(home_dir,'data',sub,'cal','cal*.nii.gz'))\n",
    "    for f in func:\n",
    "        run = f.split('/')[-1].split('.')[0][-1]\n",
    "        new_cal = op.join(bids_dir, sub_map[sub], 'fmap',\n",
    "                           sub_map[sub] + '_dir-opposing_run-0' + run + '_epi')\n",
    "        make_link(f,new_cal + '.nii.gz')\n",
    "\n",
    "        #deal with json file\n",
    "        json_str  = {\"PhaseEncodingDirection\": \"j-\", \n",
    "                     \"TotalReadoutTime\": 0.034,\n",
    "                     \"IntendedFor\": \"func/\" + sub_map[sub] + \"_task-mag_run-0\" + run + \"_bold.nii.gz\"}\n",
    "        \n",
    "        with open(new_cal + '.json', 'w') as outfile:\n",
    "            json.dump(json_str, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Something had mucked up the HDR files and incorrectly specified the TR as 1 second\n",
    "for sub in sub_list:\n",
    "    func = glob.glob(op.join(home_dir,'data',sub,'func','run*.nii.gz'))\n",
    "    for f in func:\n",
    "        #copy header to file\n",
    "        run = f.split('/')[-1].split('.')[0][-1]\n",
    "        out_hdr = op.join(home_dir,'hdrs',sub + '_' + run +'.txt')\n",
    "        cmd = ['fslhd', '-x', f, '>', out_hdr]\n",
    "        cmd = ' '.join(cmd)\n",
    "        os.system(cmd)\n",
    "        \n",
    "        #edit TR\n",
    "        out_hdr2 = op.join(home_dir,'hdrs',sub + '_' + run +'edit.txt')\n",
    "        with open(out_hdr, \"rt\") as fin:\n",
    "            with open(out_hdr2, \"wt\") as fout:\n",
    "                for line in fin:\n",
    "                    fout.write(line.replace('dt = \\'1\\'', 'dt = \\'2\\''))\n",
    "        \n",
    "        #write header\n",
    "        cmd = ['fslcreatehd', out_hdr2, f]\n",
    "        cmd = ' '.join(cmd)\n",
    "        os.system(cmd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
